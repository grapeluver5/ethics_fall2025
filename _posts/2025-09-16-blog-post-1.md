---
title: 'Blog 1: Ethical Frameworks'
date: 2025-09-16
permalink: /posts/2025/09/blog-post-1/
tags:
  - article
  - blog post
  - AI
  - ethics
---

Many user's private Grok chats were released; though they may have unknowingly consented to it.

**Article:**  
[Your Chats With AI Chatbot Grok May Be Visible to Everyone](https://www.cnet.com/tech/your-chats-with-ai-chatbot-grok-may-be-visible-to-all/)

My Thoughts Out Loud
---
Though I don't personally use Grok (and am not an avid user of LLMs in general), I know multiple family members and friends who do, so I chose this article to better understand some of the privacy concerns with using such a service. A big concern for me with these services is that most Terms of Use agreements relinquish the ownership of any content that users provide it, while simultaneously attempting to exonerate themselves of any blame when their models are problematic. While users technically agree to the release of information they'd otherwise assume to be private, they're unlikely to know since it's detailed among loads of other terms most won't ever read through.

---
The primary stakeholder then is the user, with x.com and privacy experts being the other two main entities to consider here. Users are the focus in this article, as their information is what's at stake. They should be concerned not just about chats being made available to the public, but the other uses permitted to in the usage agreement. The release of such info is not good, but it may open users' eyes to speculate on what else their info is being used for. As mentioned in the article, users are able to delete chat history with Grok, but that will likely not delete already-published info. In this case, it's especially concerning then that potentially highly-private information has no way to be scrubbed by users themselves.

x.com has a big stake here as well, as the reactions to this situation will at the very least indirectly affect their model going forward. Currently, they're not required to be very explicit in the data they're collecting. This could change, however, as petitions from users may force them to change their policies around data collection and publishing. 

Finally, it's clear that because this technology is still relatively new, implementations of it are still half-baked. That means that whatever is deemed acceptible and unacceptible to users will set a large precedent moving forward, which is why privacy experts should be mindful of how situations like these are responded to. The future of AI integration into personal life is being shaped as we know it, and they're most certainly concerned about the implications of Big Tech inviding privacy to this degree (and users openly accepting this invation).

Applying Frameworks
---
hello everyone my name is markiplier


Final Reflection
---
tee hee hahaha
