---
title: 'Blog 2: Crafting Arguments'
date: 2025-09-21
permalink: /posts/2025/09/blog-post-2/
tags:
  - article
  - academia
  - AI
  - opinion
---

Universities are now starting to allow the usage of LLMs to assist in assignments; does this give them the responsibility to teach appropriate usage?

**Article:**  
[AI is now part of our world. Uni graduates should know how to use it responsibly](https://theconversation.com/ai-is-now-part-of-our-world-uni-graduates-should-know-how-to-use-it-responsibly-261273)

"The Conversation"s Argument
---
Premise 1: “Artificial intelligence is rapidly becoming an everyday part of lives”
Premise 2:  Australian universities are allowing students to use AI for assignments
Premise 3: Allowing AI usage makes students susceptible to misinformation, bias, and ethical issues.
Conclusion: “All students should graduate with a basic understanding of AI… and what responsible use looks like in their particular field.”

Considerations
---
P1 & 2 Challenge: Multiple examples of AI usage in daily life do not utilize the same technology present in current-day LLMs. Along with that, much of the integration of AI tools into modern software is involuntary, and the presence of it does not guarantee it will be used. This applies to academic settings too, as permitting students to use AI technologies will not mean that everyone will begin to use it.
P3 Challenge: Students will more than likely already be exposed to lots of misinformation and bias in media much more complex than anything present in AI; educating them to accurately identify these things within a context of being able to challenge them is far more important than understanding when an LLM generates incorrect information.

More conclusively, this article falls prey to bandwagoning, arguing that the forced injection of AI by companies into every aspect of our lives means we should be explicitly taught to accept it as is and learn when it could be wrong, instead of more-broadly educating students on ethical issues already present in media and society and inderectly being equipped to identify such issues also present in AI.

Alternative Solution
---
I do agree that students who plan to use AI to assist with their work should understand the limitations it has, but not all students need to be equipped with this knowledge as not everyone is going to use it. In regards to the ethical dilemmas posed by these language models, it would go a much longer way to teach students to identify misinformation and bias in media; that way everyone has something to gain, and those who are using AI will still meet the criteria set by the article. This is all to say that ethics should be taught outside of the AI bubble so it’s inclusive to people in every field. AI has the power to reduce the monotony of many jobs, but it shouldn’t be treated as the be-all-end-all of efficiency, and shouldn’t be discussed as a firm requirement for everyone to use now.

Final Reflection
---
The hardest part of this assignment for me was finding a source to report on, as it seemed many articles in the spreadsheet didn’t take a definitive stance on the issue they were talking about, and those that did were more often than not paywalled. The one I did land on though took a firm stance, and provided arguments feasible for this exercise. I think I did well identifying the biggest fallacy present, though again not sure if I wrote too much or too little. It was also sort of tough “suggesting how the technology should be used” since I do agree that those who wish to use AI should know its limits, but more so disagreed that everyone needed that sort of education (so I instead gave an alternative to the education solution they provided).
